-> semi-supervised learning problem (generate label to training files, and predict labels on testing files)

-> The main consideration is OpCode, as it defines the behavior of malware.

=> Feature engineering
    ------------------------
 The primary features extracted are OpCode, segments, pixel intensity along with the secondary features such as file size, and character count. Once the features are extracted, the images are formed 

 -> Deep learning models are used for learning the images generated by the features. Finally, the Region of Interest (ROI) is identified which helped in malware detection
    ===========================
 -> This phase deals with extracting the features from ASM files
and selecting the appropriate features with the support of ran-
dom forest.

-> Three primary features, i.e., OpCode, Segment, pixel
count, along with secondary features such as number of lines and
number of characters in a file, are analyzed.



=> Opcode analysis
------------------------

-> Retrieval of OpCode is done easily as it is first non-byte in the
line.

-> Once all the OpCode of one ASM file are retrieved, then the
count of each OpCode is computed.

-> The count is not sufficient to analyze the de-fragmented presence of malware. For depth observation of these OpCode, the PageRank methodology is used.

-> PageRank algorithm is used to determine the authenticity of unigram bigram, trigram and quadrigram. For example, let the OpCode be’pop-push-add-new’. The PageRank algorithm determines the score for all the different 4 terms present in this code. Th scores computed for‘pop’, ‘push’, ‘add’, ‘new’ are 0.672, 0.613.0.623, 0.698 respectively. So, when the score for each term of OpCode lies in the same domain,that the particular OpCode is acceptable and proceeded to the next step. So, after applying PageRank methodology, the acceptable OpCodes are filtered fro those unreliable OpCodes.

---------------------------------

Segment analysis
=======================
-> In this context, Segment refers to the starting text of the line in ASM file. By executing a single line of code, it is easy to fetch the first keyword of the line. These segments are classified as Header, text, code, and data. In total 448 segments are retrieved in the training dataset. By applying the feature selection technique on these segments computed features, 26 segments are selected from the total segments 

ASM pixel count
==========================

=> in byte files, the value of each element is between 0 and 255. Together with the ASM files, we can easily convert these byte files to gray scale images. The first 800-pixel densities of ASM files are observed to have a significant impact on the final result. The presentation of ASM file is done using boxplot



Image conversion
--------------------

-> A filtered malicious binary code is read by our method as a vector of 8-bit unsigned integers. 

->Thus, a vector was transformed into a 2D array.

-> We applied the pixel-to-pixel transformation with color depth of two pixels on the visualized malware binary and the 2D array to form gray-scale images

-> Depending on the file size, the height of the malware’s image is allowed to vary and the malware’s image width is set along with the image density.


Deep learning
-----------------------

The CNN model is trained with the images produced in the
previous phase


=>> ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone.

==> dense layers -->
In any neural network, a dense layer is a layer that is deeply connected with its preceding layer which means the neurons of the layer are connected to every neuron of its preceding layer. This layer is the most commonly used layer in artificial neural network networks.

The dense layer’s neuron in a model receives output from every neuron of its preceding layer, where neurons of the dense layer perform matrix-vector multiplication


CNN
===================

A Convolutional Neural Network (ConvNet/CNN) is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other.
 The pre-processing required in a ConvNet is much lower as compared to other classification algorithms. While in primitive methods filters are hand-engineered, with enough training, ConvNets have the ability to learn these filters/characteristics.